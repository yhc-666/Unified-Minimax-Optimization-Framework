Dataset: yahoo
Metrics: auc (maximize), mse (minimize), ndcg_5 (maximize), ndcg_10 (maximize)
Number of trials: 100
Number of Pareto optimal solutions: 4

============================================================
PARETO OPTIMAL SOLUTIONS
============================================================

Pareto Solution #1 (Trial 51):
----------------------------------------
Objective values:
  auc: 0.716396
  mse: 0.236352
  ndcg_5: 0.695527
  ndcg_10: 0.800127

All metrics:
  mse: 0.236352
  mae: 0.461553
  auc: 0.716396
  ndcg_5: 0.695527
  precision_5: 0.279630
  recall_5: 0.454294
  f1_5: 0.346178
  ndcg_10: 0.800127
  precision_10: 0.231833
  recall_10: 0.726296
  f1_10: 0.351476
  ndcg: 0.695527
  precision: 0.279630
  recall: 0.454294
  f1: 0.346178
  training_time: 264.870911

Parameters:
  batch_size: 4096
  gamma: 0.025201592042024667
  G: 4
  beta: 5
  num_bins: 20
  embedding_k: 32
  embedding_k1: 64
  pred_lr: 0.005
  impu_lr: 0.01
  prop_lr: 0.005
  dis_lr: 0.01
  lamb_pred: 0.00010371623066591883
  lamb_imp: 0.04186232026213231
  lamb_prop: 0.007338565959284677
  dis_lamb: 0.012473901691973321
  abc_model_name: mlp

Pareto Solution #2 (Trial 73):
----------------------------------------
Objective values:
  auc: 0.716621
  mse: 0.237502
  ndcg_5: 0.696263
  ndcg_10: 0.800697

All metrics:
  mse: 0.237502
  mae: 0.467205
  auc: 0.716621
  ndcg_5: 0.696263
  precision_5: 0.279000
  recall_5: 0.455287
  f1_5: 0.345982
  ndcg_10: 0.800697
  precision_10: 0.231833
  recall_10: 0.726296
  f1_10: 0.351476
  ndcg: 0.696263
  precision: 0.279000
  recall: 0.455287
  f1: 0.345982
  training_time: 370.253157

Parameters:
  batch_size: 4096
  gamma: 0.041656910721200854
  G: 4
  beta: 5
  num_bins: 20
  embedding_k: 64
  embedding_k1: 64
  pred_lr: 0.005
  impu_lr: 0.01
  prop_lr: 0.005
  dis_lr: 0.01
  lamb_pred: 0.0001250458138197331
  lamb_imp: 0.044308132163111566
  lamb_prop: 0.009487836196902083
  dis_lamb: 0.008615927736974316
  abc_model_name: logistic_regression

Pareto Solution #3 (Trial 80):
----------------------------------------
Objective values:
  auc: 0.716814
  mse: 0.237558
  ndcg_5: 0.694832
  ndcg_10: 0.800248

All metrics:
  mse: 0.237558
  mae: 0.468465
  auc: 0.716814
  ndcg_5: 0.694832
  precision_5: 0.277926
  recall_5: 0.452792
  f1_5: 0.344436
  ndcg_10: 0.800248
  precision_10: 0.231833
  recall_10: 0.726296
  f1_10: 0.351476
  ndcg: 0.694832
  precision: 0.277926
  recall: 0.452792
  f1: 0.344436
  training_time: 426.655988

Parameters:
  batch_size: 4096
  gamma: 0.04818940979358159
  G: 4
  beta: 100
  num_bins: 10
  embedding_k: 64
  embedding_k1: 64
  pred_lr: 0.005
  impu_lr: 0.01
  prop_lr: 0.005
  dis_lr: 0.01
  lamb_pred: 0.00012134279475786205
  lamb_imp: 0.027296034412063318
  lamb_prop: 0.004374349575836426
  dis_lamb: 0.011919896274539925
  abc_model_name: logistic_regression

Pareto Solution #4 (Trial 82):
----------------------------------------
Objective values:
  auc: 0.716855
  mse: 0.237408
  ndcg_5: 0.693717
  ndcg_10: 0.799682

All metrics:
  mse: 0.237408
  mae: 0.468386
  auc: 0.716855
  ndcg_5: 0.693717
  precision_5: 0.277741
  recall_5: 0.451600
  f1_5: 0.343948
  ndcg_10: 0.799682
  precision_10: 0.231833
  recall_10: 0.726296
  f1_10: 0.351476
  ndcg: 0.693717
  precision: 0.277741
  recall: 0.451600
  f1: 0.343948
  training_time: 422.041082

Parameters:
  batch_size: 4096
  gamma: 0.04863819469325701
  G: 4
  beta: 100
  num_bins: 10
  embedding_k: 64
  embedding_k1: 64
  pred_lr: 0.005
  impu_lr: 0.01
  prop_lr: 0.005
  dis_lr: 0.01
  lamb_pred: 0.00012055265726761058
  lamb_imp: 0.028724205114519143
  lamb_prop: 0.005601192595126563
  dis_lamb: 0.013071008175036095
  abc_model_name: logistic_regression

